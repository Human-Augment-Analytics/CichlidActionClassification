{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Applying a ConvLSTM network on the MC16_2 dataset\n",
        "\n",
        "This code extracts and processes video data from Dropbox, moves it to Google Drive, and builds a deep learning model to classify the videos. Frames are extracted from each video, resized, and padded if necessary. Labels are encoded, and the dataset is split into training and testing sets. A ConvLSTM network, combining convolutional layers and LSTM layers, is built to capture both spatial and temporal features. The model is trained on the dataset and evaluated to determine its accuracy in classifying the videos based on predefined labels. This approach is useful for tasks involving video classification and activity recognition.\n",
        "\n",
        "![flowchart](Figures/week5-flowchart.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRJBkDMPPJCs"
      },
      "source": [
        "## Phase I: Setting Up rClone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgNVyH0JJPDw"
      },
      "source": [
        "The following code performs several steps related to installing and configuring `rclone`, a command-line tool for managing files on cloud storage. Here is a step-by-step explanation of what each part of the code does:\n",
        "\n",
        "1.   **Install `rclone` and other necessary tools:**\n",
        "\n",
        "  *   The `wget` command downloads the latest version of `rclone` for Linux in a zip file.\n",
        "  *   The `unzip` command extracts the contents of the zip file.\n",
        "  *   The `mkdir -p ~/bin` command creates a `bin` in the home directory if it doesn't already exist.\n",
        "  *   The `mv` command moves the `rclone` executable to the `~bin` directory.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lx7dFlnKU-jj",
        "outputId": "8bdd9ba2-8d32-41c2-c235-83ff5b1af813"
      },
      "outputs": [],
      "source": [
        "# Install rclone and other necessary tools\n",
        "!wget https://downloads.rclone.org/rclone-current-linux-amd64.zip -O rclone.zip\n",
        "!unzip rclone.zip\n",
        "!mkdir -p ~/bin\n",
        "!mv rclone-*-linux-amd64/rclone ~/bin/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHCyrzO1K39x"
      },
      "source": [
        "2.   **Update the PATH environment variable:**\n",
        "\n",
        "  *   The `os.environ[\"PATH\"]` line appends the `~/bin` directory to the PATH environment variable, ensuring that the `rclone` command can be executed from anywhere.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6Y1pPJxVmN5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Add the ~/bin directory to the PATH environment variable\n",
        "os.environ[\"PATH\"] += os.pathsep + os.path.expanduser(\"~/bin\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nU95E_lLavv"
      },
      "source": [
        "3.   **Verify `rclone` installation:**\n",
        "\n",
        "  *   This command checks if `rclone` has been successfully installed by printing its version.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Wd_LrrJVodC",
        "outputId": "280c0d0d-e2b4-40eb-d21a-1d26c3a7f2b1"
      },
      "outputs": [],
      "source": [
        "# Verify rclone is in the PATH\n",
        "!rclone version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbdLOnLyLxm_"
      },
      "source": [
        "4.   **Configure `rclone` with Dropbox:**\n",
        "\n",
        "  *   The `config_content` variable contains the configuration for a Dropbox remote named `cichlidVideo`.\n",
        "  *   The `with open('rclone.conf', 'w') as config_file:` line writes this configuration to an `rclone.conf` file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVCry9_vVx3P"
      },
      "outputs": [],
      "source": [
        "config_content = \"\"\"\n",
        "[cichlidVideo]\n",
        "type = dropbox\n",
        "token = {\"access_token\":\"---\",\"token_type\":\"---\",\"expiry\":\"---\"}\n",
        "\"\"\"\n",
        "\n",
        "# Write the content to the rclone.conf file\n",
        "with open('rclone.conf', 'w') as config_file:\n",
        "    config_file.write(config_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "734kT2llMlvr"
      },
      "source": [
        "5.   **Mount Google Drive:**\n",
        "\n",
        "  *   This code mounts Google Drive to the `/content/drive` directory, making it accessible within the Colab environment.\n",
        "\n",
        "  This setup allows you to use `rclone` to manage files between local storage, Dropbox, and Google Drive within a Google Colab environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlYM0eIsV1PH",
        "outputId": "4e0b4602-b617-41fe-b474-3cec9fb3a47c"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iiLReHFPQK8"
      },
      "source": [
        "## Phase II: Moving Files Over From Dropbox"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-ONJsqSONRQ"
      },
      "source": [
        "The following code performs several tasks related to copying, extracting, and processing video clips and their labels from Dropbox to Google Drive, and then verifying and preparing these files for further analysis. Here is a step-by-step explanation of what each part of the code does:\n",
        "\n",
        "1.   **Import the `tarfile` module:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2p6JAbtYV_ks",
        "outputId": "60aaa1cc-4f64-423d-f4c3-50f0ff3c8c3e"
      },
      "outputs": [],
      "source": [
        "import tarfile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VslmHfb5PY5U"
      },
      "source": [
        "2. **Copy the `.tar` file from Dropbox to Google Drive:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_RvOkxfPh72"
      },
      "outputs": [],
      "source": [
        "# Copy the .tar file from DropBox to Google Drive\n",
        "source_path = \"BioSci-McGrath/Apps/CichlidPiData/__AnnotatedData/LabeledVideos/Clips/MC16_2.tar\"\n",
        "dest_path = \"/content/drive/MyDrive/OMSCS/Cichlids/\"\n",
        "!rclone --config rclone.conf -v copy cichlidVideo:{source_path} {dest_path}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gTdZtt2Pvyz"
      },
      "source": [
        "3. **Extract the `.tar` file in Google Drive:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "PHxrY3NAXm3K",
        "outputId": "0688c6a8-3fff-44a0-9a56-bfc7a2897795"
      },
      "outputs": [],
      "source": [
        "tar_file_path = \"/content/drive/MyDrive/OMSCS/Cichlids/MC16_2.tar\"\n",
        "dest_path_extract = \"/content/drive/MyDrive/OMSCS/Cichlids/unzipped\"\n",
        "\n",
        "# Open and extract the tar file\n",
        "with tarfile.open(tar_file_path, 'r') as tar:\n",
        "  tar.extractall(path=dest_path_extract)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxnpmzCqP2ds"
      },
      "source": [
        "4. **Verify the extraction:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2B2aFxy4P2mJ"
      },
      "outputs": [],
      "source": [
        "# Verify the extraction\n",
        "!ls -l /content/drive/MyDrive/OMSCS/Cichlids/unzipped"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXX-n7lXQEqO"
      },
      "source": [
        "5. **Copy the CSV file with manual labels from Dropbox to Google Drive:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2bJZTt2iY6H",
        "outputId": "29787056-4a64-4cf4-fdfd-79fba7f4bed1"
      },
      "outputs": [],
      "source": [
        "source_labels = \"BioSci-McGrath/Apps/CichlidPiData/__AnnotatedData/LabeledVideos/ManualLabels.csv\"\n",
        "dest_path_labels = \"/content/drive/MyDrive/OMSCS/Cichlids/\"\n",
        "!rclone --config rclone.conf -v copy cichlidVideo:{source_labels} {dest_path_labels}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tn_XaxkMQRVG"
      },
      "source": [
        "6. **Read the CSV file into a DataFrame:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jeZ7Unzmi3aN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Path to the CSV file on Google Drive\n",
        "csv_path = \"/content/drive/MyDrive/OMSCS/Cichlids/ManualLabels.csv\"\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df = pd.read_csv(csv_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKtRtlcCQexh"
      },
      "source": [
        "7. **Add the full path to each file in the DataFrame:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cU8SOZxoQXuW"
      },
      "outputs": [],
      "source": [
        "# Adding the full path to each file\n",
        "base_path = \"/content/drive/MyDrive/OMSCS/Cichlids/unzipped/MC16_2/\"\n",
        "df['full_path'] = base_path + df['ClipName']\n",
        "\n",
        "# Print the DataFrame\n",
        "#print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcqQdrw1Qw5M"
      },
      "source": [
        "8. **Print the unique manual labels (commented out):**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVhi3Qu_WQxw"
      },
      "outputs": [],
      "source": [
        "unique_manual_labels = df['ManualLabel'].unique()\n",
        "#print(unique_manual_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdXMoe_xQ6NG"
      },
      "source": [
        "9. **Verify the files in the target directory:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwLwhlEzjQsg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Path to the target directory on Google Drive\n",
        "target_dir = \"/content/drive/MyDrive/OMSCS/Cichlids/unzipped/MC16_2\"\n",
        "\n",
        "# List all files in the target directory\n",
        "files_in_directory = os.listdir(target_dir)\n",
        "\n",
        "# Display the first few files to verify\n",
        "#print(files_in_directory[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lk_lXY7nRNlu"
      },
      "source": [
        "10. **Prepare the list of files to process with their corresponding manual labels:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRa5wJm8jsa0",
        "outputId": "992952ce-d1f6-4084-96e8-1a91e4a6996d"
      },
      "outputs": [],
      "source": [
        "# Extract the ClipName column from the DataFrame\n",
        "clip_names = df['ClipName'].tolist()\n",
        "manual_labels = df['ManualLabel'].tolist()\n",
        "\n",
        "files_to_process = []\n",
        "\n",
        "# Check which ClipName values are present in the directory\n",
        "for file in files_in_directory:\n",
        "    for clip_name, manual_label in zip(clip_names, manual_labels):\n",
        "      if clip_name in file:\n",
        "        #files_to_process.append([file for clip in clip_names if clip in file])\n",
        "        files_to_process.append({'file': base_path + file, 'manual_label': manual_label})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sp1ILSiKRfHO"
      },
      "source": [
        "11. **Display the files to process with their corresponding manual labels (commented out):**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RtOTXR7RECc"
      },
      "outputs": [],
      "source": [
        "# Display the files to process with their corresponding manual labels\n",
        "\"\"\"\n",
        "print(\"Files to process with Manual Labels:\")\n",
        "for item in files_to_process:\n",
        "    print(f\"File: {item['file']}, Manual Label: {item['manual_label']}\")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uK-yNyklRueO"
      },
      "source": [
        "12. **Print the first file to process and the total number of files:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNPi3xhhRcmj"
      },
      "outputs": [],
      "source": [
        "print(files_to_process[0])\n",
        "print(f\"Number of files: {len(files_to_process)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFDy-cuWR5PU"
      },
      "source": [
        "The above setup allows you to efficiently manage and process video clips and their labels from Dropbox to Google Drive with a Google Colab environment, preparing them for subsequent analysis or processing steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcWxd0EySOQ-"
      },
      "source": [
        "## Phase III: Training The Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulp4-x0qSSgN"
      },
      "source": [
        "This code performs a sequence of tasks to load and preprocess video data, build a neural network model, train it, and evaluate its performance. Below is a detailed step-by-step breakdown:\n",
        "\n",
        "1. **Loading the Libraries:**\n",
        "\n",
        "  *   This section imports necessary libraries for file handling, image processing, numerical operations, data manipulation, and building a deep learning model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfXAOWPbkPWu"
      },
      "outputs": [],
      "source": [
        "# Loading the libraries\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, LSTM, TimeDistributed\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbL7BTa0UQKE"
      },
      "source": [
        "2. **Set Parameters:**\n",
        "\n",
        "  *   These variables define the dimensions of frames extracted from videos and the number of frames to be extracted from each video.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkAuMhnBks7N"
      },
      "outputs": [],
      "source": [
        "frame_width = 64\n",
        "frame_height = 64\n",
        "num_frames = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cL9JRLVUyPP"
      },
      "source": [
        "3. **Function to Extract Frames from Videos:**\n",
        "\n",
        "  *   This function reads a video file, resizes the frames to the specified dimensions, and collects a fixed number of frames. If the video has fewer frames that required, it pads the sequence with black frames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoxmT1KHUn2M"
      },
      "outputs": [],
      "source": [
        "# Extract frames from videos\n",
        "def extract_frames(video_path, frame_width, frame_height, num_frames):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frames = []\n",
        "    while len(frames) < num_frames:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame = cv2.resize(frame, (frame_width, frame_height))\n",
        "        frames.append(frame)\n",
        "    cap.release()\n",
        "    # If the video has fewer frames, pad with black frames\n",
        "    while len(frames) < num_frames:\n",
        "        frames.append(np.zeros((frame_height, frame_width, 3), dtype=np.uint8))\n",
        "    return np.array(frames[:num_frames])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6TuJQDdVQ_L"
      },
      "source": [
        "4. **Function to Create the Dataset:**\n",
        "\n",
        "  *   This function preprocesses a list of video files and their corresponding labels, extracting frames from each video and storing them along with their labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKTwVr29Uuxe"
      },
      "outputs": [],
      "source": [
        "def create_dataset(files_to_process, frame_width, frame_height, num_frames):\n",
        "    X = []\n",
        "    y = []\n",
        "    for file_info in files_to_process:\n",
        "        video_path = file_info['file']\n",
        "        label = file_info['manual_label']\n",
        "        frames = extract_frames(video_path, frame_width, frame_height, num_frames)\n",
        "        X.append(frames)\n",
        "        y.append(label)\n",
        "    return np.array(X), np.array(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTB8L6N1VmM2"
      },
      "source": [
        "5. **Example Usage to Create Dataset:**\n",
        "\n",
        "  *   Here, the dataset is created by calling the `create_dataset` function with the list of files to process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTlTnoYxVmVr"
      },
      "outputs": [],
      "source": [
        "# Example usage\n",
        "X, y = create_dataset(files_to_process, frame_width, frame_height, num_frames)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBJpD6IhV-5R"
      },
      "source": [
        "6. **Encode Labels:**\n",
        "\n",
        "  *   Labels are mapped to numerical values and then converted to categorical format using one-hot-encoding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Bh5Dda3cfwg"
      },
      "outputs": [],
      "source": [
        "label_mapping = {'m': 0, 'o': 1, 'c': 2, 'p': 3, 'd': 4, 'x': 5, 'f': 6, 't': 7, 'b': 8, 's': 9}\n",
        "y = np.array([label_mapping[label] for label in y])\n",
        "y = to_categorical(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKoreSRsWT0w"
      },
      "source": [
        "7. **Split Dataset into Training and Testing Sets:**\n",
        "\n",
        "  *   The dataset is split into training and testing sets with 80% of the data used for training and 20% for testing.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHgU8ZyidG5T"
      },
      "outputs": [],
      "source": [
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfffnobyWquh"
      },
      "source": [
        "8. **Build the Model:**\n",
        "  * The model is defined as a sequential stack of layers:\n",
        "    * `TimeDistributed` wrapper to apply the same convolutional and pooling operations to each frame.\n",
        "    * An LSTM layer to process the sequences of frames.\n",
        "    * A dense layer with softmax activation to output class probabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9aEWhxMdMMV",
        "outputId": "42d736c0-9094-4c9b-fd64-08a4da0f7198"
      },
      "outputs": [],
      "source": [
        "# Build model\n",
        "model = Sequential([\n",
        "    TimeDistributed(Conv2D(32, (3, 3), activation='relu'), input_shape=(num_frames, frame_height, frame_width, 3)),\n",
        "    TimeDistributed(MaxPooling2D((2, 2))),\n",
        "    TimeDistributed(Flatten()),\n",
        "    LSTM(64, activation='relu'),\n",
        "    Dense(len(label_mapping), activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWcwEWjLXStp"
      },
      "source": [
        "9. **Compile the Model:**\n",
        "\n",
        "  * The model is compiled with Adam optimizer and categorical cross-entropy loss, with accuracy as a metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_uc-S1udVFo"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RO6jpfLXhVm"
      },
      "source": [
        "10. **Train the Model:**\n",
        "\n",
        "  * The model is trained on the training data for 100 epochs, using the test data for validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AozaRzRWeXMv",
        "outputId": "52e1a2e7-c875-4829-ec75-cada7bfdaea4"
      },
      "outputs": [],
      "source": [
        "# Train model\n",
        "history = model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEswRTI6Xxp5"
      },
      "source": [
        "11. **Evaluate the Model:**\n",
        "\n",
        "  * The model's performance is evaluated on the test set, and the test accuracy is printed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbAMauZyeZ35",
        "outputId": "429a24a9-2864-4403-85f6-43420cbc03c6"
      },
      "outputs": [],
      "source": [
        "# Evaluate model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIJVfeT4YE0E"
      },
      "source": [
        "This comprehensive process involves extracting frames from videos, preparing the dataset, building a deep learning model, and evaluating its performance, all within a Google Colab environment."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "bRJBkDMPPJCs"
      ],
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
