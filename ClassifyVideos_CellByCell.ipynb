{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify Videos, the .ipynb version\n",
    "\n",
    "<p>A cell-by-cell breakdown of how this script functions in addition to all changes made so far.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Imports, directory, and parser set-up\n",
    "\n",
    "Before executing this section, please go to your bash terminal and run `pip install torch torchvision`. There were circumstances when adding arguments to the parser that I would get an error due to the default parameter. It was set to `os.getenv(\"HOME\")`, which would return `None` when I ran it. This happens in some environments, particularly on Windows, where `HOME` is not a standard environment. To handle this, I provided a fallback for the `HOME` environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, subprocess, datetime, os, pdb, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils.CichlidActionRecognition import ML_model\n",
    "from Utils.DataPrepare import DP_worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the HOME environment variable, with a fallback to the user's directory on Windows\n",
    "home_dir = os.getenv(\"HOME\") or os.path.expanduser(\"~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='This script takes a model, and apply this model to new video clips')\n",
    "needsDir = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Input data\n",
    "\n",
    "The setup below helps make the script more flexible and user-friendly by allowing users to specify different directories for their various files, while ensuring that necessary directories are created if they don't already exist.\n",
    "\n",
    "- `--Input_videos_directory` is the directory that holds all the labeled videos.\n",
    "- `--Videos_to_project_file` (.csv) is a mapping of video clips to the project each animal belongs to.\n",
    "- `--Trained_model_file` (.pth) is the data saved from the previous training.\n",
    "- `--Trained_categories_file` (.json) was previously used for training.\n",
    "- `--Training_options` (.log) was previously used for training.\n",
    "- `--Output_file` (.csv) details the confidence and label for each video clip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory of video clips\n",
    "parser.add_argument('--Input_videos_directory',\n",
    "                    type = str, \n",
    "                    default = os.path.join(home_dir,'data/labeled_videos'),\n",
    "                    required = False, \n",
    "                    help = 'Name of directory to hold all video clips')\n",
    "needsDir.append(\"Input_videos_directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping of video clips to project\n",
    "parser.add_argument('--Videos_to_project_file',\n",
    "                    type = str, \n",
    "                    default = os.path.join(home_dir,'data/videoToProject.csv'),\n",
    "                    help = 'Project each animal belongs to')\n",
    "needsDir.append(\"Videos_to_project_file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the previous training's model results\n",
    "parser.add_argument('--Trained_model_file',\n",
    "                    default = os.path.join(home_dir,'data/model.pth'),\n",
    "                    type = str,\n",
    "                    help = 'Save data (.pth) of previous training')\n",
    "needsDir.append(\"Trained_model_file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON file previously used for training\n",
    "parser.add_argument('--Trained_categories_file',\n",
    "                    type = str, \n",
    "                    default = os.path.join(home_dir,'data/train.json'),\n",
    "                    help = 'JSON file previously used for training')\n",
    "needsDir.append(\"Trained_categories_file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log file used for training\n",
    "parser.add_argument('--Training_options_file',\n",
    "                    type = str, \n",
    "                    default = os.path.join(home_dir,'data/log_test/val.log'),\n",
    "                    help = 'log file in training')\n",
    "needsDir.append(\"Training_options_file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output CSV that details the confidence and label for each video clip \n",
    "parser.add_argument('--Output_file',\n",
    "                    type = str, \n",
    "                    default = os.path.join(home_dir,'data/confusionMatrix.csv'),\n",
    "                    help = 'CSV file that keeps the confidence and label for each video clip')\n",
    "needsDir.append(\"Output_file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C) Temporary directories\n",
    "\n",
    "These comprise temporary clips and files that would be deleted by the end of the analysis. Including more details below:\n",
    "\n",
    "- `--Temporary_clips_directory` represent the location for the temporary clips to be stored.\n",
    "- `--Temporary_output_directory` is the location for the temporary files to be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of temporary clips\n",
    "parser.add_argument('--Temporary_clips_directory',\n",
    "                    default = os.path.join(home_dir,'data/clips_temp'),\n",
    "                    type = str, \n",
    "                    required = False, \n",
    "                    help = 'Location for temp clips to be stored')\n",
    "needsDir.append(\"Temporary_clips_directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of temporary files\n",
    "parser.add_argument('--Temporary_output_directory',\n",
    "                    default = os.path.join(home_dir,'data/intermediate_temp'),\n",
    "                    type = str, \n",
    "                    required = False, \n",
    "                    help = 'Location for temp files to be stored')\n",
    "needsDir.append(\"Temporary_output_directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D) Arguments that don't require a file to be passed in\n",
    "\n",
    "These are parser arguments that don't require a file to be passed in. These are typically hyperparameters that will be useful for training the model later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--gpu_card'], dest='gpu_card', nargs=None, const=None, default='1', type=<class 'str'>, choices=None, required=False, help='gpu card to use', metavar=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Purpose of the script\n",
    "parser.add_argument('--Purpose',\n",
    "                    type = str, \n",
    "                    default = 'classify',\n",
    "                    help = 'classify is the only function for this script for now')\n",
    "\n",
    "# Batch size for the model\n",
    "parser.add_argument('--batch_size', \n",
    "                    default=13, \n",
    "                    type=int, help='Batch Size')\n",
    "\n",
    "# Number of workers\n",
    "parser.add_argument('--n_threads',\n",
    "                    default=5,\n",
    "                    type=int,\n",
    "                    help='Number of threads for multi-thread loading')\n",
    "\n",
    "# GPU card to use\n",
    "parser.add_argument('--gpu_card',\n",
    "                    default='1',\n",
    "                    type=str,\n",
    "                    help='gpu card to use')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--sample_size'], dest='sample_size', nargs=None, const=None, default=120, type=<class 'int'>, choices=None, required=False, help='Height and width of inputs', metavar=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similar parameters, but these are for the dataloader\n",
    "\n",
    "# The sample duration of each inputted clip\n",
    "parser.add_argument('--sample_duration',\n",
    "                    default=96,\n",
    "                    type=int,\n",
    "                    help='Temporal duration of inputs')\n",
    "\n",
    "# Standardized height and width of inputs                    \n",
    "parser.add_argument('--sample_size',\n",
    "                    default=120,\n",
    "                    type=int,\n",
    "                    help='Height and width of inputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--resnet_shortcut'], dest='resnet_shortcut', nargs=None, const=None, default='B', type=None, choices=None, required=False, help='Shortcut type of resnet (A | B)', metavar=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters for the optimizer\n",
    "parser.add_argument('--learning_rate', default=0.1, type=float, help='Initial learning rate (divided by 10 while training by lr scheduler)')\n",
    "parser.add_argument('--momentum', default=0.9, type=float, help='Momentum')\n",
    "parser.add_argument('--dampening', default=0.9, type=float, help='dampening of SGD')\n",
    "parser.add_argument('--weight_decay', default=1e-5, type=float, help='Weight Decay')\n",
    "parser.add_argument('--nesterov', action='store_true', help='Nesterov momentum')\n",
    "parser.set_defaults(nesterov = False)\n",
    "parser.add_argument('--optimizer', default='sgd', type=str, help='Currently only support SGD')\n",
    "parser.add_argument('--lr_patience', default=10, type=int, help='Patience of LR scheduler. See documentation of ReduceLROnPlateau.')\n",
    "parser.add_argument('--resnet_shortcut', default='B', help='Shortcut type of resnet (A | B)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--n_classes'], dest='n_classes', nargs=None, const=None, default=10, type=<class 'int'>, choices=None, required=False, help=None, metavar=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters specific for training from scratch\n",
    "parser.add_argument('--n_classes', default=10, type=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E) Output Data\n",
    "\n",
    "This is the directory where we would store all the sample logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the results directory\n",
    "parser.add_argument('--Results_directory',\n",
    "                    type = str,\n",
    "                    default = os.path.join(home_dir,'data/results_dir_temp'),\n",
    "                    help = 'directory to store sample prepare logs')\n",
    "needsDir.append(\"Results_directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F) Helper module that creates the required directories\n",
    "\n",
    "In a Jupyter notebook, additional arguments (e.g., related to the Jupyter kernel) might be passed, which are not recognized by the script's argument parser. `parse_known_args()` helps to avoid errors by ignoring unrecognized arguments.\n",
    "\n",
    "The other code blocks ensure that specific directories or file paths exist before performing operations that rely on them. If the directories or file paths do not exist, the code creates them.\n",
    "\n",
    "And finally, the code iterates through a list called `needsDir`, which contains the names of directories or file paths that are required. For each item, it retrieves the corresponding path from the `args` object. If the item refers to a file path, it ensures that the directory for that file exists. If the item refers to a directory path, it ensures the directory exists. If any directory does not exist, the script creates it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code below is needed if you're running this script from a Jupyter notebook\n",
    "if 'ipykernel_launcher' in sys.argv[0]:\n",
    "    args, unknown = parser.parse_known_args()\n",
    "else:\n",
    "    args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if a directory exists, and create it if it doesn't\n",
    "def ensure_directory_exists(path):\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Path does not exist, creating path: {path}\")\n",
    "        os.makedirs(path)\n",
    "    print(f\"Using directory: {path}\")\n",
    "    \n",
    "# Function to check if a file's directory exists, and create it if it doesn't\n",
    "def ensure_file_directory_exists(file_path):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        print(f\"Directory for the file does not exist, creating directory: {directory}\")\n",
    "        os.makedirs(directory)\n",
    "    print(f\"Using file path: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path does not exist, creating path: /home/hice1/kpatherya3/data/labeled_videos\n",
      "Using directory: /home/hice1/kpatherya3/data/labeled_videos\n",
      "Using file path: /home/hice1/kpatherya3/data/videoToProject.csv\n",
      "Using file path: /home/hice1/kpatherya3/data/model.pth\n",
      "Using file path: /home/hice1/kpatherya3/data/train.json\n",
      "Directory for the file does not exist, creating directory: /home/hice1/kpatherya3/data/log_test\n",
      "Using file path: /home/hice1/kpatherya3/data/log_test/val.log\n",
      "Using file path: /home/hice1/kpatherya3/data/confusionMatrix.csv\n",
      "Path does not exist, creating path: /home/hice1/kpatherya3/data/clips_temp\n",
      "Using directory: /home/hice1/kpatherya3/data/clips_temp\n",
      "Path does not exist, creating path: /home/hice1/kpatherya3/data/intermediate_temp\n",
      "Using directory: /home/hice1/kpatherya3/data/intermediate_temp\n",
      "Path does not exist, creating path: /home/hice1/kpatherya3/data/results_dir_temp\n",
      "Using directory: /home/hice1/kpatherya3/data/results_dir_temp\n"
     ]
    }
   ],
   "source": [
    "# Creating directories for every item in needsDir if it doesn't exist\n",
    "for nDir in needsDir:\n",
    "    arg_value = getattr(args, nDir)\n",
    "    if nDir.endswith('_file'):\n",
    "        ensure_file_directory_exists(arg_value)\n",
    "    else:\n",
    "        ensure_directory_exists(arg_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G) rClone Set-Up\n",
    "\n",
    "With the directory structure set-up, it's time to import the files from DropBox, and we leverage rClone to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i) Setting up rClone within this notebook\n",
    "\n",
    "The following code block downloads rClone, and prints out the version to verify that the installation was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-05-30 22:05:32--  https://downloads.rclone.org/rclone-current-linux-amd64.zip\n",
      "Resolving downloads.rclone.org (downloads.rclone.org)... 95.217.6.16, 2a01:4f9:c012:7154::1\n",
      "Connecting to downloads.rclone.org (downloads.rclone.org)|95.217.6.16|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 21137057 (20M) [application/zip]\n",
      "Saving to: ‘rclone.zip’\n",
      "\n",
      "rclone.zip          100%[===================>]  20.16M  14.2MB/s    in 1.4s    \n",
      "\n",
      "2024-05-30 22:05:34 (14.2 MB/s) - ‘rclone.zip’ saved [21137057/21137057]\n",
      "\n",
      "Archive:  rclone.zip\n",
      "   creating: rclone-v1.66.0-linux-amd64/\n",
      "  inflating: rclone-v1.66.0-linux-amd64/README.html  \n",
      "  inflating: rclone-v1.66.0-linux-amd64/README.txt  \n",
      "  inflating: rclone-v1.66.0-linux-amd64/rclone  \n",
      "  inflating: rclone-v1.66.0-linux-amd64/git-log.txt  \n",
      "  inflating: rclone-v1.66.0-linux-amd64/rclone.1  \n",
      "rclone v1.66.0\n",
      "- os/version: redhat 9.3 (64 bit)\n",
      "- os/kernel: 5.14.0-362.24.1.el9_3.x86_64 (x86_64)\n",
      "- os/type: linux\n",
      "- os/arch: amd64\n",
      "- go/version: go1.22.1\n",
      "- go/linking: static\n",
      "- go/tags: none\n"
     ]
    }
   ],
   "source": [
    "!wget https://downloads.rclone.org/rclone-current-linux-amd64.zip -O rclone.zip\n",
    "!unzip rclone.zip\n",
    "!mkdir -p ~/bin\n",
    "!mv rclone-*-linux-amd64/rclone ~/bin/\n",
    "\n",
    "# Add the ~/bin directory to the PATH environment variable\n",
    "os.environ[\"PATH\"] += os.pathsep + os.path.expanduser(\"~/bin\")\n",
    "\n",
    "# Verify rclone is in the PATH\n",
    "!rclone version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii) Editing the rClone configuration file\n",
    "\n",
    "Connecting to the BioSci-McGrath DropBox folder. Token codes have been masked to prevent any leaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_content = \"\"\"\n",
    "[cichlidVideo]\n",
    "type = dropbox\n",
    "token = {\"access_token\":\"---\",\"token_type\":\"---\",\"expiry\":\"---\"}\n",
    "\"\"\"\n",
    "\n",
    "# Write the content to the rclone.conf file\n",
    "with open('rclone.conf', 'w') as config_file:\n",
    "    config_file.write(config_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii) Testing the DropBox connection\n",
    "\n",
    "Listing files of a random directory within the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       14 hosts.secret\r\n",
      "       15 pi_password.secret\r\n",
      "      177 rclone.conf\r\n",
      "       69 sendgrid_key.secret\r\n"
     ]
    }
   ],
   "source": [
    "random_path = \"BioSci-McGrath/Apps/CichlidPiData/__CredentialFiles/iof_credentials\"\n",
    "!rclone --config rclone.conf ls cichlidVideo:{random_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iv) Copying files over to the relevant directory\n",
    "\n",
    "Including a set of files that could be used by the ML model. I will revise these paths as I receive more direction.\n",
    "\n",
    "##### a) Input Data\n",
    "\n",
    "These are the files that will be necessary to have before running the model.\n",
    "\n",
    "- `.../labeled_videos/` is the directory that holds all the labeled videos.\n",
    "- `.../videoToProject.csv` (.csv) is a mapping of video clips to the project each animal belongs to.\n",
    "- `.../model.pth` (.pth) is the data saved from the previous training.\n",
    "- `.../train.json` (.json) was previously used for training.\n",
    "- `.../log_test/val.log` (.log) was previously used for training.\n",
    "- `.../confusionMatrix.csv` (.csv) details the confidence and label for each video clip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: get the correct paths\n",
    "\n",
    "videos_path = \"BioSci-McGrath/Apps/CichlidPiData/__AnnotatedData/LabeledVideos/Clips\"\n",
    "vid_to_proj_path = \"BioSci-McGrath/Apps/CichlidPiData/__MachineLearningModels/3DResnet/MCsingle_nuc/videoToProject.csv\"\n",
    "trained_model = \"BioSci-McGrath/Apps/CichlidPiData/__MachineLearningModels/3DResnet/MCsingle_nuc/model.pth\"\n",
    "trained_categories = \"BioSci-McGrath/Apps/CichlidPiData/__MachineLearningModels/3DResnet/Model18_All/Lijiang_best_model/train.json\"\n",
    "training_options = \"BioSci-McGrath/Apps/CichlidPiData/__MachineLearningModels/3DResnet/MCsingle_nuc/val.log\"\n",
    "output_file = \"BioSci-McGrath/Apps/CichlidPiData/__MachineLearningModels/3DResnet/MCsingle_nuc/confusionMatrix.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/05/30 22:05:38 INFO  : ._TI2_4.y4oZPj: Copied (new)\n",
      "2024/05/30 22:05:39 INFO  : MC_singlenuc21_6_Tk53_030320.tar: Copied (new)\n",
      "2024/05/30 22:05:46 INFO  : MC_singlenuc23_8_Tk33_031720.tar: Copied (new)\n",
      "2024/05/30 22:05:50 INFO  : MC_singlenuc28_1_Tk3_022520.tar: Copied (new)\n",
      "2024/05/30 22:05:51 INFO  : MC_singlenuc29_3_Tk9_030320.tar: Copied (new)\n",
      "2024/05/30 22:05:52 INFO  : MC6_5.tar: Multi-thread Copied (new)\n",
      "2024/05/30 22:05:54 INFO  : MC_singlenuc35_11_Tk61_051220.tar: Copied (new)\n",
      "2024/05/30 22:05:55 INFO  : MC_singlenuc36_2_Tk3_030320.tar: Copied (new)\n",
      "2024/05/30 22:05:56 INFO  : MC_singlenuc41_2_Tk9_030920.tar: Copied (new)\n",
      "2024/05/30 22:05:56 INFO  : MC_singlenuc46_2_Tk53_030920.tar: Copied (new)\n",
      "2024/05/30 22:05:58 INFO  : MC_singlenuc54_5_Tk53_051220.tar: Copied (new)\n",
      "2024/05/30 22:05:59 INFO  : MC_singlenuc50_5_Tk9_050720.tar: Copied (new)\n",
      "2024/05/30 22:06:00 INFO  : CV10_3.tar: Multi-thread Copied (new)\n",
      "2024/05/30 22:06:01 INFO  : MC16_2.tar: Multi-thread Copied (new)\n",
      "2024/05/30 22:06:06 INFO  : MC_singlenuc62_3_Tk65_060220.tar: Copied (new)\n",
      "2024/05/30 22:06:13 INFO  : MCxCVF1_12a_1.tar: Multi-thread Copied (new)\n",
      "2024/05/30 22:06:23 INFO  : TI3_3.tar: Multi-thread Copied (new)\n",
      "2024/05/30 22:06:23 INFO  : MCxCVF1_12b_1.tar: Multi-thread Copied (new)\n",
      "2024/05/30 22:06:24 INFO  : TI2_4.tar: Multi-thread Copied (new)\n",
      "2024/05/30 22:06:24 INFO  : \n",
      "Transferred:   \t    4.326 GiB / 4.326 GiB, 100%, 74.656 MiB/s, ETA 0s\n",
      "Transferred:           19 / 19, 100%\n",
      "Elapsed time:        46.7s\n",
      "\n",
      "2024/05/30 22:06:24 INFO  : Dropbox root 'BioSci-McGrath/Apps/CichlidPiData/__AnnotatedData/LabeledVideos/Clips': Committing uploads - please wait...\n",
      "2024/05/30 22:06:24 INFO  : videoToProject.csv: Copied (new)\n",
      "2024/05/30 22:06:24 INFO  : \n",
      "Transferred:   \t    2.408 MiB / 2.408 MiB, 100%, 0 B/s, ETA -\n",
      "Transferred:            1 / 1, 100%\n",
      "Elapsed time:         0.7s\n",
      "\n",
      "2024/05/30 22:06:24 INFO  : Dropbox root 'BioSci-McGrath/Apps/CichlidPiData/__MachineLearningModels/3DResnet/MCsingle_nuc': Committing uploads - please wait...\n",
      "2024/05/30 22:06:30 INFO  : model.pth: Copied (new)\n",
      "2024/05/30 22:06:30 INFO  : \n",
      "Transferred:   \t  253.434 MiB / 253.434 MiB, 100%, 63.365 MiB/s, ETA 0s\n",
      "Transferred:            1 / 1, 100%\n",
      "Elapsed time:         5.0s\n",
      "\n",
      "2024/05/30 22:06:30 INFO  : Dropbox root 'BioSci-McGrath/Apps/CichlidPiData/__MachineLearningModels/3DResnet/MCsingle_nuc': Committing uploads - please wait...\n",
      "2024/05/30 22:06:31 INFO  : train.json: Copied (new)\n",
      "2024/05/30 22:06:31 INFO  : \n",
      "Transferred:   \t    1.109 MiB / 1.109 MiB, 100%, 0 B/s, ETA -\n",
      "Transferred:            1 / 1, 100%\n",
      "Elapsed time:         1.0s\n",
      "\n",
      "2024/05/30 22:06:31 INFO  : Dropbox root 'BioSci-McGrath/Apps/CichlidPiData/__MachineLearningModels/3DResnet/Model18_All/Lijiang_best_model': Committing uploads - please wait...\n",
      "2024/05/30 22:06:32 INFO  : val.log: Copied (new)\n",
      "2024/05/30 22:06:32 INFO  : \n",
      "Transferred:   \t    5.416 KiB / 5.416 KiB, 100%, 0 B/s, ETA -\n",
      "Transferred:            1 / 1, 100%\n",
      "Elapsed time:         1.0s\n",
      "\n",
      "2024/05/30 22:06:32 INFO  : Dropbox root 'BioSci-McGrath/Apps/CichlidPiData/__MachineLearningModels/3DResnet/MCsingle_nuc': Committing uploads - please wait...\n",
      "2024/05/30 22:06:33 INFO  : confusionMatrix.csv: Copied (new)\n",
      "2024/05/30 22:06:33 INFO  : \n",
      "Transferred:   \t        482 B / 482 B, 100%, 0 B/s, ETA -\n",
      "Transferred:            1 / 1, 100%\n",
      "Elapsed time:         0.8s\n",
      "\n",
      "2024/05/30 22:06:33 INFO  : Dropbox root 'BioSci-McGrath/Apps/CichlidPiData/__MachineLearningModels/3DResnet/MCsingle_nuc': Committing uploads - please wait...\n"
     ]
    }
   ],
   "source": [
    "!rclone --config rclone.conf -v copy cichlidVideo:{videos_path} data/labeled_videos/\n",
    "!rclone --config rclone.conf -v copy cichlidVideo:{vid_to_proj_path} data/\n",
    "!rclone --config rclone.conf -v copy cichlidVideo:{trained_model} data/\n",
    "!rclone --config rclone.conf -v copy cichlidVideo:{trained_categories} data/\n",
    "!rclone --config rclone.conf -v copy cichlidVideo:{training_options} data/log_test/\n",
    "!rclone --config rclone.conf -v copy cichlidVideo:{output_file} data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with data worker and ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Location'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:153\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:182\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Location'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m ML_model \u001b[38;5;241m=\u001b[39m ML_model(args)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mML_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Utils/CichlidActionRecognition.py:52\u001b[0m, in \u001b[0;36mML_model.work\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m     source_annotateData \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(opt\u001b[38;5;241m.\u001b[39mML_labels, sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, header \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 52\u001b[0m source_annotation_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[43msource_annotateData\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLocation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m,source_annotateData[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMeanID\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# training data loader\u001b[39;00m\n\u001b[1;32m     57\u001b[0m crop_method \u001b[38;5;241m=\u001b[39m MultiScaleRandomCenterCrop([\u001b[38;5;241m0.99\u001b[39m,\u001b[38;5;241m0.97\u001b[39m,\u001b[38;5;241m0.95\u001b[39m,\u001b[38;5;241m0.93\u001b[39m,\u001b[38;5;241m0.91\u001b[39m],opt\u001b[38;5;241m.\u001b[39msample_size)\n",
      "File \u001b[0;32m/usr/local/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages/pandas/core/frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/usr/local/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages/pandas/core/indexes/base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3805\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3806\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3807\u001b[0m     ):\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3809\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3811\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3812\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Location'"
     ]
    }
   ],
   "source": [
    "ML_model = ML_model(args)\n",
    "ML_model.work()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert video clips to images for faster loading\n",
      "calculate mean file\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot set a DataFrame with multiple columns to the single column MeanID",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m data_worker \u001b[38;5;241m=\u001b[39m DP_worker(args)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdata_worker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Utils/DataPrepare.py:231\u001b[0m, in \u001b[0;36mDP_worker.work\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwork\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 231\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata conversion done, split data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_data()\n",
      "File \u001b[0;32m~/Utils/DataPrepare.py:63\u001b[0m, in \u001b[0;36mDP_worker.prepare_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     61\u001b[0m dt \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(means_all_file,sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     62\u001b[0m annotation_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(annotation_file,sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 63\u001b[0m dt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMeanID\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m dt\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: annotation_df\u001b[38;5;241m.\u001b[39mloc[annotation_df\u001b[38;5;241m.\u001b[39mLocation\u001b[38;5;241m==\u001b[39mrow\u001b[38;5;241m.\u001b[39mClip]\u001b[38;5;241m.\u001b[39mMeanID\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m], axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     64\u001b[0m means \u001b[38;5;241m=\u001b[39m dt\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMeanID\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(means_file,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m/usr/local/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages/pandas/core/frame.py:4289\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4287\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array(key, value)\n\u001b[1;32m   4288\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[0;32m-> 4289\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item_frame_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4290\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m   4291\u001b[0m     is_list_like(value)\n\u001b[1;32m   4292\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique\n\u001b[1;32m   4293\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_indexer_for([key])) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(value)\n\u001b[1;32m   4294\u001b[0m ):\n\u001b[1;32m   4295\u001b[0m     \u001b[38;5;66;03m# Column to set is duplicated\u001b[39;00m\n\u001b[1;32m   4296\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n",
      "File \u001b[0;32m/usr/local/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages/pandas/core/frame.py:4447\u001b[0m, in \u001b[0;36mDataFrame._set_item_frame_value\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4444\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misetitem(locs, value)\n\u001b[1;32m   4446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 4447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   4448\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot set a DataFrame with multiple columns to the single \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4449\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4450\u001b[0m     )\n\u001b[1;32m   4451\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   4452\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   4453\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot set a DataFrame without columns to the column \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4454\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot set a DataFrame with multiple columns to the single column MeanID"
     ]
    }
   ],
   "source": [
    "data_worker = DP_worker(args)\n",
    "data_worker.work()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu_card\n",
    "print(os.environ[\"CUDA_VISIBLE_DEVICES\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
