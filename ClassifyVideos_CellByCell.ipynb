{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify Videos, the .ipynb version\n",
    "\n",
    "<p>A cell-by-cell breakdown of how this script functions in addition to all changes made so far.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Imports, directory, and parser set-up\n",
    "\n",
    "Before executing this section, please go to your bash terminal and run `pip install torch torchvision`. There were circumstances when adding arguments to the parser that I would get an error due to the default parameter. It was set to `os.getenv(\"HOME\")`, which would return `None` when I ran it. This happens in some environments, particularly on Windows, where `HOME` is not a standard environment. To handle this, I provided a fallback for the `HOME` environment variable.\n",
    "\n",
    "Now that I've switched to Google Colab, you would need to switch to the `content` folder and add the CichlidActionClassification repository to it. The sys and home_dir variable should be updated as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, subprocess, datetime, os, pdb, sys\n",
    "!ls /content/CichlidActionClassification/\n",
    "sys.path.append('/content/CichlidActionClassification/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = \"/content\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='This script takes a model, and apply this model to new video clips')\n",
    "needsDir = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Input data\n",
    "\n",
    "The setup below helps make the script more flexible and user-friendly by allowing users to specify different directories for their various files, while ensuring that necessary directories are created if they don't already exist.\n",
    "\n",
    "- `--Input_videos_directory` is the directory that holds all the labeled videos.\n",
    "- `--Videos_to_project_file` (.csv) is a mapping of video clips to the project each animal belongs to.\n",
    "- `--Trained_model_file` (.pth) is the data saved from the previous training.\n",
    "- `--Trained_categories_file` (.json) was previously used for training.\n",
    "- `--Training_options` (.log) was previously used for training.\n",
    "- `--Output_file` (.csv) details the confidence and label for each video clip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory of video clips\n",
    "parser.add_argument('--Input_videos_directory',\n",
    "                    type = str, \n",
    "                    default = os.path.join(home_dir,'data/labeled_videos'),\n",
    "                    required = False, \n",
    "                    help = 'Name of directory to hold all video clips')\n",
    "needsDir.append(\"Input_videos_directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping of video clips to project\n",
    "parser.add_argument('--Videos_to_project_file',\n",
    "                    type = str, \n",
    "                    default = os.path.join(home_dir,'data/videoToProject.csv'),\n",
    "                    help = 'Project each animal belongs to')\n",
    "needsDir.append(\"Videos_to_project_file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the previous training's model results\n",
    "parser.add_argument('--Trained_model_file',\n",
    "                    default = os.path.join(home_dir,'data/model.pth'),\n",
    "                    type = str,\n",
    "                    help = 'Save data (.pth) of previous training')\n",
    "needsDir.append(\"Trained_model_file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON file previously used for training\n",
    "parser.add_argument('--Trained_categories_file',\n",
    "                    type = str, \n",
    "                    default = os.path.join(home_dir,'data/train.json'),\n",
    "                    help = 'JSON file previously used for training')\n",
    "needsDir.append(\"Trained_categories_file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log file used for training\n",
    "parser.add_argument('--Training_options_file',\n",
    "                    type = str, \n",
    "                    default = os.path.join(home_dir,'data/log_test/val.log'),\n",
    "                    help = 'log file in training')\n",
    "needsDir.append(\"Training_options_file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output CSV that details the confidence and label for each video clip \n",
    "parser.add_argument('--Output_file',\n",
    "                    type = str, \n",
    "                    default = os.path.join(home_dir,'data/confusionMatrix.csv'),\n",
    "                    help = 'CSV file that keeps the confidence and label for each video clip')\n",
    "needsDir.append(\"Output_file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C) Temporary directories\n",
    "\n",
    "These comprise temporary clips and files that would be deleted by the end of the analysis. Including more details below:\n",
    "\n",
    "- `--Temporary_clips_directory` represent the location for the temporary clips to be stored.\n",
    "- `--Temporary_output_directory` is the location for the temporary files to be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of temporary clips\n",
    "parser.add_argument('--Temporary_clips_directory',\n",
    "                    default = os.path.join(home_dir,'data/clips_temp'),\n",
    "                    type = str, \n",
    "                    required = False, \n",
    "                    help = 'Location for temp clips to be stored')\n",
    "needsDir.append(\"Temporary_clips_directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of temporary files\n",
    "parser.add_argument('--Temporary_output_directory',\n",
    "                    default = os.path.join(home_dir,'data/intermediate_temp'),\n",
    "                    type = str, \n",
    "                    required = False, \n",
    "                    help = 'Location for temp files to be stored')\n",
    "needsDir.append(\"Temporary_output_directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D) Arguments that don't require a file to be passed in\n",
    "\n",
    "These are parser arguments that don't require a file to be passed in. These are typically hyperparameters that will be useful for training the model later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose of the script\n",
    "parser.add_argument('--Purpose',\n",
    "                    type = str, \n",
    "                    default = 'classify',\n",
    "                    help = 'classify is the only function for this script for now')\n",
    "\n",
    "# Batch size for the model\n",
    "parser.add_argument('--batch_size', \n",
    "                    default=13, \n",
    "                    type=int, help='Batch Size')\n",
    "\n",
    "# Number of workers\n",
    "parser.add_argument('--n_threads',\n",
    "                    default=5,\n",
    "                    type=int,\n",
    "                    help='Number of threads for multi-thread loading')\n",
    "\n",
    "# GPU card to use\n",
    "parser.add_argument('--gpu_card',\n",
    "                    default='1',\n",
    "                    type=str,\n",
    "                    help='gpu card to use')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar parameters, but these are for the dataloader\n",
    "\n",
    "# The sample duration of each inputted clip\n",
    "parser.add_argument('--sample_duration',\n",
    "                    default=96,\n",
    "                    type=int,\n",
    "                    help='Temporal duration of inputs')\n",
    "\n",
    "# Standardized height and width of inputs                    \n",
    "parser.add_argument('--sample_size',\n",
    "                    default=120,\n",
    "                    type=int,\n",
    "                    help='Height and width of inputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the optimizer\n",
    "parser.add_argument('--learning_rate', default=0.1, type=float, help='Initial learning rate (divided by 10 while training by lr scheduler)')\n",
    "parser.add_argument('--momentum', default=0.9, type=float, help='Momentum')\n",
    "parser.add_argument('--dampening', default=0.9, type=float, help='dampening of SGD')\n",
    "parser.add_argument('--weight_decay', default=1e-5, type=float, help='Weight Decay')\n",
    "parser.add_argument('--nesterov', action='store_true', help='Nesterov momentum')\n",
    "parser.set_defaults(nesterov = False)\n",
    "parser.add_argument('--optimizer', default='sgd', type=str, help='Currently only support SGD')\n",
    "parser.add_argument('--lr_patience', default=10, type=int, help='Patience of LR scheduler. See documentation of ReduceLROnPlateau.')\n",
    "parser.add_argument('--resnet_shortcut', default='B', help='Shortcut type of resnet (A | B)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters specific for training from scratch\n",
    "parser.add_argument('--n_classes', default=10, type=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E) Output Data\n",
    "\n",
    "This is the directory where we would store all the sample logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the results directory\n",
    "parser.add_argument('--Results_directory',\n",
    "                    type = str,\n",
    "                    default = os.path.join(home_dir,'data/results_dir_temp'),\n",
    "                    help = 'directory to store sample prepare logs')\n",
    "needsDir.append(\"Results_directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F) Helper module that creates the required directories\n",
    "\n",
    "In a Jupyter notebook, additional arguments (e.g., related to the Jupyter kernel) might be passed, which are not recognized by the script's argument parser. `parse_known_args()` helps to avoid errors by ignoring unrecognized arguments. This applies to Google Colab as well.\n",
    "\n",
    "The other code blocks ensure that specific directories or file paths exist before performing operations that rely on them. If the directories or file paths do not exist, the code creates them.\n",
    "\n",
    "And finally, the code iterates through a list called `needsDir`, which contains the names of directories or file paths that are required. For each item, it retrieves the corresponding path from the `args` object. If the item refers to a file path, it ensures that the directory for that file exists. If the item refers to a directory path, it ensures the directory exists. If any directory does not exist, the script creates it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you're running this script from a Jupyter/Colab notebook\n",
    "if 'ipykernel_launcher' in sys.argv[0] or 'colab_kernel_launcher' in sys.argv[0]:\n",
    "    args, unknown = parser.parse_known_args()\n",
    "else:\n",
    "    args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if a directory exists, and create it if it doesn't\n",
    "def ensure_directory_exists(path):\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Path does not exist, creating path: {path}\")\n",
    "        os.makedirs(path)\n",
    "    print(f\"Using directory: {path}\")\n",
    "    \n",
    "# Function to check if a file's directory exists, and create it if it doesn't\n",
    "def ensure_file_directory_exists(file_path):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        print(f\"Directory for the file does not exist, creating directory: {directory}\")\n",
    "        os.makedirs(directory)\n",
    "    print(f\"Using file path: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating directories for every item in needsDir if it doesn't exist\n",
    "for nDir in needsDir:\n",
    "    arg_value = getattr(args, nDir)\n",
    "    if nDir.endswith('_file'):\n",
    "        ensure_file_directory_exists(arg_value)\n",
    "    else:\n",
    "        ensure_directory_exists(arg_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G) rClone Set-Up\n",
    "\n",
    "With the directory structure set-up, it's time to import the files from DropBox, and we leverage rClone to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i) Setting up rClone within this notebook\n",
    "\n",
    "The following code block downloads rClone, and prints out the version to verify that the installation was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://downloads.rclone.org/rclone-current-linux-amd64.zip -O rclone.zip\n",
    "!unzip rclone.zip\n",
    "!mkdir -p ~/bin\n",
    "!mv rclone-*-linux-amd64/rclone ~/bin/\n",
    "\n",
    "# Add the ~/bin directory to the PATH environment variable\n",
    "os.environ[\"PATH\"] += os.pathsep + os.path.expanduser(\"~/bin\")\n",
    "\n",
    "# Verify rclone is in the PATH\n",
    "!rclone version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii) Editing the rClone configuration file\n",
    "\n",
    "Connecting to the BioSci-McGrath DropBox folder. Token codes have been masked to prevent any leaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_content = \"\"\"\n",
    "[cichlidVideo]\n",
    "type = dropbox\n",
    "token = {\"access_token\":\"---\",\"token_type\":\"---\",\"expiry\":\"---\"}\n",
    "\"\"\"\n",
    "\n",
    "# Write the content to the rclone.conf file\n",
    "with open('rclone.conf', 'w') as config_file:\n",
    "    config_file.write(config_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii) Testing the DropBox connection\n",
    "\n",
    "Listing files of a random directory within the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_path = \"BioSci-McGrath/Apps/CichlidPiData/__CredentialFiles/iof_credentials\"\n",
    "!rclone --config rclone.conf ls cichlidVideo:{random_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iv) Copying files over to the relevant directory\n",
    "\n",
    "Including a set of files that could be used by the ML model. I will revise these paths as I receive more direction.\n",
    "\n",
    "##### a) Input Data\n",
    "\n",
    "These are the files that will be necessary to have before running the model.\n",
    "\n",
    "- `.../labeled_videos/` is the directory that holds all the labeled videos.\n",
    "- `.../videoToProject.csv` (.csv) is a mapping of video clips to the project each animal belongs to.\n",
    "- `.../model.pth` (.pth) is the data saved from the previous training.\n",
    "- `.../train.json` (.json) was previously used for training.\n",
    "- `.../log_test/val.log` (.log) was previously used for training.\n",
    "- `.../confusionMatrix.csv` (.csv) details the confidence and label for each video clip.\n",
    "\n",
    "This list is being updated through trial and error, as I find the correct DropBox files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: get the correct paths\n",
    "\n",
    "videos_path = \"BioSci-McGrath/Apps/CichlidPiData/__AnnotatedData/LabeledVideos/Clips\"\n",
    "vid_to_proj_path = \"BioSci-McGrath/Apps/CichlidPiData/__MachineLearningModels/3DResnet/MCsingle_nuc/videoToProject.csv\"\n",
    "trained_model = \"BioSci-McGrath/Apps/CichlidPiData/__MachineLearningModels/3DResnet/MCsingle_nuc/model.pth\"\n",
    "trained_categories = \"BioSci-McGrath/Apps/CichlidPiData/__MachineLearningModels/3DResnet/Model18_All/Lijiang_best_model/train.json\"\n",
    "trained_means = \"BioSci-McGrath/Apps/CichlidPiData/__ArchivedData/__MachineLearning/Models/modelAll_18/Means.csv\"\n",
    "cichlid_json = \"BioSci-McGrath/Apps/CichlidPiData/__ArchivedData/__MachineLearning/Models/modelAll_18/cichlids.json\"\n",
    "training_options = \"BioSci-McGrath/Apps/CichlidPiData/__MachineLearningModels/3DResnet/MCsingle_nuc/val.log\"\n",
    "output_file = \"BioSci-McGrath/Apps/CichlidPiData/__MachineLearningModels/3DResnet/MCsingle_nuc/confusionMatrix.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rclone --config rclone.conf -v copy cichlidVideo:{videos_path} data/labeled_videos/\n",
    "!rclone --config rclone.conf -v copy cichlidVideo:{vid_to_proj_path} data/\n",
    "!rclone --config rclone.conf -v copy cichlidVideo:{trained_model} data/\n",
    "!rclone --config rclone.conf -v copy cichlidVideo:{trained_categories} data/\n",
    "!rclone --config rclone.conf -v copy cichlidVideo:{training_options} data/log_test/\n",
    "!rclone --config rclone.conf -v copy cichlidVideo:{output_file} data/\n",
    "!rclone --config rclone.conf -v copy cichlidVideo:{trained_means} data/results_dir_temp/\n",
    "!rclone --config rclone.conf -v copy cichlidVideo:{cichlid_json} data/results_dir_temp/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with data worker and ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CichlidActionRecognitionScript.py is the new script I wrote for testing purposes\n",
    "\n",
    "from Utils.CichlidActionRecognitionScript import ML_model\n",
    "ML_model = ML_model(args)\n",
    "ML_model.work()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils.DataPrepare import DP_worker\n",
    "data_worker = DP_worker(args)\n",
    "data_worker.work()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu_card\n",
    "print(os.environ[\"CUDA_VISIBLE_DEVICES\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
